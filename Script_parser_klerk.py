# –°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Å–∞–π—Ç–∞ Klerk
import ssl
import requests
import pickle
from bs4 import BeautifulSoup
import time
import math
from csv import writer
from random import randint
from time import sleep
import re

from requests.adapters import HTTPAdapter
from requests.packages.urllib3.poolmanager import PoolManager
from requests.packages.urllib3.util import ssl_

CIPHERS = """ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:AES256-SHA"""

class TlsAdapter(HTTPAdapter):

    def __init__(self, ssl_options=0, **kwargs):
        self.ssl_options = ssl_options
        super(TlsAdapter, self).__init__(**kwargs)

    def init_poolmanager(self, *pool_args, **pool_kwargs):
        ctx = ssl_.create_urllib3_context(ciphers=CIPHERS, cert_reqs=ssl.CERT_REQUIRED, options=self.ssl_options)
        self.poolmanager = PoolManager(*pool_args, ssl_context=ctx, **pool_kwargs)

session = requests.session()
adapter = TlsAdapter(ssl.OP_NO_TLSv1 | ssl.OP_NO_TLSv1_1)
session.mount("https://", adapter)

url_scrapping = 'https://www.klerk.ru/news/sort/month_best/page/'

# –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
amount_pages = 47

# –û–±—Ä–∞—â–∞–µ–º—Å—è –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ
for p in range(amount_pages):

    url_accurate = url_scrapping + str(p + 1) + '/' # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–æ—á–Ω—ã–π URL

    html_text_page = session.request('GET', url_accurate).text   # –ü–æ–ª—É—á–∏–º –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
    html_text_page_xml = BeautifulSoup(html_text_page, 'lxml')

    if not ( '–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω' in html_text_page ) :
        print("–°–∫—Ä–∞–ø–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Ññ: %d" % (p + 1))

        header_all_ads_on_page = html_text_page_xml.find_all('article', class_ = 'feed-item feed-item--normal')
        data = []

        for i in range(len( header_all_ads_on_page) ):
            # –≤—ã–¥–µ–ª–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å
            link_poln = str( header_all_ads_on_page[i].find('a', class_ = 'feed-item__link feed-item-link__check-article') )
            symbol_start = link_poln.find('href=')
            symbol_end = link_poln.find('/">')
            link = 'https://www.klerk.ru' + link_poln[symbol_start+6 : symbol_end ] + '/'

            # –í—ã–¥–µ–ª–∏–º –Ω–æ–º–µ—Ä –Ω–æ–≤–æ—Å—Ç–∏
            number_news =  link_poln[symbol_start+16 : symbol_end ]
            header_news = str( header_all_ads_on_page[i].find('a', class_ = 'feed-item__link feed-item-link__check-article').text )
            header_news_clear = re.sub("[üìí|‚ö°|üé§|üî•|‚ùó|‚úã|;|üëö|üçù|üòÅ|üì§|üçØ|‚òéÔ∏è|üôâ|üêå|üí∏|‚ú®|üöó|üêÆ|üçÖ|üìÑ|‚úÖ|üîé|üìú|üè¶|üë™|üìû|üëé|üí•|‚úçÔ∏è|üë∑|üé∞|üôÜ|üí£|üìå|üöó|üöø|üò±|üí∞|üö©|üíª|‚ùé|üìà|üëÜ|üëØ|üìú]","",header_news)

            # –í—ã–¥–µ–ª–∏–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            time = str( header_all_ads_on_page[i].find('span', class_ = 'stats-block') )
            symbol_start2 = time.find('date=')
            symbol_end2 = time.find('></core')
            time_clear =  time[symbol_start2+6 : symbol_end2 -1 ]

            # –í—ã–¥–µ–ª–∏–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            short_description = str( header_all_ads_on_page[i].find('div', class_ = 'feed-item__content').text ).strip()

            # –í—ã–¥–µ–ª–∏–º —Ä—É–±—Ä–∏–∫—É
            rrr = header_all_ads_on_page[i].find('a', class_ = 'feed-item__rubric')
            if rrr != None :
                rubrication = str( rrr.text )
            else:
                rubrication = '–Ω–µ—Ç'

            # –í—ã–¥–µ–ª–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            for_comments = str( header_all_ads_on_page[i].find('div', class_ = 'feed-item__footer-stat') )
            symbol_start3 = for_comments.find('comments-button')
            symbol_end3 = for_comments.find('#comments">')
            comments = for_comments[symbol_start3 +24 : symbol_end3 -25 ]

            # –í—ã–¥–µ–ª–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
            symbol_start4 = for_comments.find('core-count-format')
            symbol_end4 = for_comments.find('></core-count-format>')
            view = for_comments[symbol_start4 +25 : symbol_end4 -1 ]

            # –ü–æ–º–µ—Å—Ç–∏–º –¥–∞–Ω–Ω—ã–µ –≤ –º–∞—Å—Å–∏–≤
            data.append([number_news, link, time_clear, rubrication, comments, view, header_news_clear, short_description])

        # –ü–æ–º–µ—Å—Ç–∏–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª
        with open('links_with_short_descriptions.csv', 'a', encoding='utf-8', newline='') as f_object:
            writer_object = writer(f_object, delimiter=';')
            for r in range(len(header_all_ads_on_page)):
                writer_object.writerow(data[r])

            f_object.close()

    else:
        print('IP –≤—Ä–µ–º–µ–Ω–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω')

    sleep(randint(7,12))

print('–í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã')
